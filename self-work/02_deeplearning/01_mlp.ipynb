{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "load_dotenv()\n",
    "# Mac Modified! add PYTHONPATH variable to .env file and set to root project directory\n",
    "sys.path.insert(0, os.getenv(\"PYTHONPATH\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 18:34:44.415700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mac Modified! import tensorflow & keras independently\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers, utils, datasets\n",
    "from notebooks.utils import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2-1. Processing the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test,y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding the labels: convert 1 column label to 10 column labels\n",
    "y_train = utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36862746"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2-1. green channel (1) value of the pixel at (12, 13) of image 54\n",
    "x_train[54, 12, 13, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Model\n",
    " Example 2-4. Building our MLP using functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 18:35:17.623747: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: AMD Radeon Pro 5300M\n",
      "2023-09-09 18:35:17.623781: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-09-09 18:35:17.623789: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 1.99 GB\n",
      "2023-09-09 18:35:17.623848: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-09-09 18:35:17.623889: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input((32, 32, 3))\n",
    "\n",
    "x = layers.Flatten()(input_layer)\n",
    "x = layers.Dense(200, activation=\"relu\")(x)\n",
    "x = layers.Dense(150, activation=\"relu\")(x)\n",
    "\n",
    "output_layer = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               614600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1510      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 646260 (2.47 MB)\n",
      "Trainable params: 646260 (2.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Note**:  these parameters in above summary output, are the total number of inputs to  all the neuron units in the hidden layers._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: training model with GPU (tensorflow-metal manages the load to the GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 18:35:57.149886: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-09 18:35:57.203808: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 51s 31ms/step - loss: 2.0791 - accuracy: 0.2726\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 2.0943 - accuracy: 0.2954\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.4144 - accuracy: 0.2779\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9037 - accuracy: 0.2592\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 3.4049 - accuracy: 0.2492\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 4.0105 - accuracy: 0.2435\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 4.8345 - accuracy: 0.2343\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 5.6873 - accuracy: 0.2278\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 6.7306 - accuracy: 0.2239\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 7.5030 - accuracy: 0.2210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa961b19310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8462 - accuracy: 0.3349\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6604 - accuracy: 0.4071\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5874 - accuracy: 0.4339\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5364 - accuracy: 0.4507\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5025 - accuracy: 0.4663\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4711 - accuracy: 0.4760\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4467 - accuracy: 0.4834\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4225 - accuracy: 0.4914\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4030 - accuracy: 0.4997\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3870 - accuracy: 0.5062\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU'):\n",
    "    input_layer2 = layers.Input((32, 32, 3))\n",
    "\n",
    "    x2 = layers.Flatten()(input_layer2)\n",
    "    x2 = layers.Dense(200, activation=\"relu\")(x2)\n",
    "    x2 = layers.Dense(150, activation=\"relu\")(x2)\n",
    "\n",
    "    output_layer2 = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x2)\n",
    "\n",
    "    model2 = models.Model(input_layer2, output_layer2)\n",
    "\n",
    "    opt2 = optimizers.Adam(learning_rate=0.0005)\n",
    "    model2.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt2, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model2.fit(x_train, y_train, batch_size=32, epochs=10, shuffle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: with GPU on batch size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 19:01:00.205741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-09 19:01:00.247463: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 12s 23ms/step - loss: 2.0910 - accuracy: 0.2615\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.9427 - accuracy: 0.3186\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 1.9385 - accuracy: 0.3236\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 11s 23ms/step - loss: 1.9440 - accuracy: 0.3245\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 2.0114 - accuracy: 0.3163\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 11s 23ms/step - loss: 2.0621 - accuracy: 0.3122\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 2.1450 - accuracy: 0.3035\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 2.2527 - accuracy: 0.2949\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 2.2702 - accuracy: 0.2981\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 11s 23ms/step - loss: 2.4230 - accuracy: 0.2885\n"
     ]
    }
   ],
   "source": [
    "input_layer2 = None\n",
    "x2 = None\n",
    "output_layer2 = None\n",
    "opt2 = None\n",
    "model2 = None\n",
    "\n",
    "with tf.device('/GPU'):\n",
    "    input_layer2 = layers.Input((32, 32, 3))\n",
    "\n",
    "    x2 = layers.Flatten()(input_layer2)\n",
    "    x2 = layers.Dense(200, activation=\"relu\")(x2)\n",
    "    x2 = layers.Dense(150, activation=\"relu\")(x2)\n",
    "\n",
    "    output_layer2 = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x2)\n",
    "\n",
    "    model2 = models.Model(input_layer2, output_layer2)\n",
    "\n",
    "    opt_Adam = optimizers.Adam(learning_rate=0.0005)\n",
    "    model2.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt_Adam, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model2.fit(x_train, y_train, batch_size=100, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: with CPU on batch size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 5s 8ms/step - loss: 1.8562 - accuracy: 0.3346\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.6738 - accuracy: 0.4011\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.5945 - accuracy: 0.4342\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.5394 - accuracy: 0.4546\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.5007 - accuracy: 0.4679\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.4689 - accuracy: 0.4774\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 1.4337 - accuracy: 0.4922\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.4080 - accuracy: 0.5004\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.3887 - accuracy: 0.5074\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.3622 - accuracy: 0.5164\n"
     ]
    }
   ],
   "source": [
    "input_layer2 = None\n",
    "x2 = None\n",
    "output_layer2 = None\n",
    "opt2 = None\n",
    "model2 = None\n",
    "\n",
    "with tf.device('/CPU'):\n",
    "    input_layer2 = layers.Input((32, 32, 3))\n",
    "\n",
    "    x2 = layers.Flatten()(input_layer2)\n",
    "    x2 = layers.Dense(200, activation=\"relu\")(x2)\n",
    "    x2 = layers.Dense(150, activation=\"relu\")(x2)\n",
    "\n",
    "    output_layer2 = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x2)\n",
    "\n",
    "    model2 = models.Model(input_layer2, output_layer2)\n",
    "\n",
    "    opt_Adam = optimizers.Adam(learning_rate=0.0005)\n",
    "    model2.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt_Adam, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model2.fit(x_train, y_train, batch_size=100, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: GPU works well when batch size is more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
